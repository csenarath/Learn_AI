{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55eda496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate ,ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d5de8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chain with custom funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec365543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 1 Prompt\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "       (\"system\", \"You are a helpful assistant that is boomer\" ),\n",
    "       (\"human\", \"{input}\" )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9774fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 2 LLM\n",
    "\n",
    "llm_anthropic = ChatAnthropic(\n",
    "    model=\"claude-sonnet-4-5\",\n",
    "    api_key=API_KEY,\n",
    "    max_tokens=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07e45a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 3 STRPaser\n",
    "str_parser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ef3571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 4 [Custom Runnable]\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def dict_maker(text:str)-> dict:\n",
    "    return {\"text\":text}\n",
    "\n",
    "dict_maker_runnable = RunnableLambda(dict_maker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d66b633",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task -5 [template for Post]\n",
    "\n",
    "prompt_post_fb = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "       (\"system\", \"You are a news paper repoter for facebook\" ),\n",
    "       (\"human\", \"create a post regarding folowing {text}\" )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eabbe1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_post_nw = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "       (\"system\", \"You are a news paper repoter for news website\" ),\n",
    "       (\"human\", \"create a post regarding folowing {text}\" )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e3f0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chain \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a793ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Vietnam Veteran Shares Raw Account of Service and Homecoming\\n\\n**A Powerful Reminder: \"Some Things You Don\\'t Forget\"**\\n\\nIn a candid conversation that cuts through decades of silence, a Vietnam War veteran opened up about experiences that shaped a generationâ€”and the painful homecoming that followed.\\n\\nServing two tours in 1968-69, this veteran described the psychological toll that often exceeded the physical dangers. \"The worst of it? Not the combat, though that was hell. It was the waiting,\" he recalled, painting a vivid picture of soldiers enduring oppressive jungle humidity and constant uncertainty.\\n\\n**The Harsh Reality of Coming Home**\\n\\nPerhaps most striking was his account of returning to American soil: \"Came home in \\'69, and people spit at us. Can you believe that? We were just doing our duty, and they spit at us at the airport.\"\\n\\nThis treatment contrasts sharply with today\\'s culture of thanking veterans for their serviceâ€”a shift the veteran noted with measured irony.\\n\\n**The Silent Generation**\\n\\nHighlighting generational differences in mental health support, he explained: \"No counseling, no PTSD talk. You just buried it and moved on.\"\\n\\nHis story serves as a powerful reminder of the sacrifices made by Vietnam veterans and the importance of supporting those who serveâ€”both during and after their service.\\n\\n*What are your thoughts on how we\\'ve evolved in supporting our veterans? Share respectfully below.*\\n\\nðŸ‡ºðŸ‡¸ #VietnamVeteran #NeverForget #MilitaryHistory #VeteransVoices'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt_template | llm_anthropic | str_parser | dict_maker_runnable | prompt_post | llm_anthropic | str_parser\n",
    "\n",
    "chain.invoke({\"input\": \"what is your war story\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecc86bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fb_post(text:str)-> str:\n",
    "   prompt_post_fb = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "       (\"system\", \"You are a news paper repoter for facebook\" ),\n",
    "       (\"human\", \"create a post regarding folowing {text}\" )\n",
    "    ]\n",
    "    )\n",
    "    \n",
    "   llm_anthropic = ChatAnthropic(\n",
    "    model=\"claude-sonnet-4-5\",\n",
    "    api_key=API_KEY,\n",
    "    max_tokens=1024\n",
    "   )\n",
    "    \n",
    "   str_parser=StrOutputParser()\n",
    "   chain = prompt_post_fb | llm_anthropic | str_parser\n",
    "   \n",
    "   return chain\n",
    "\n",
    "fb_post_maker_runnable = RunnableLambda(fb_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08b36754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32ab1d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RunnableParallel.__init__() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m chain = ( prompt_template |\n\u001b[32m      2\u001b[39m         llm_anthropic | \n\u001b[32m      3\u001b[39m         str_parser |\n\u001b[32m      4\u001b[39m         dict_maker_runnable | \n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m         \u001b[43mRunnableParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfb_post_maker_runnable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprompt_post_nw\u001b[49m\u001b[43m \u001b[49m\u001b[43m|\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm_anthropic\u001b[49m\u001b[43m \u001b[49m\u001b[43m|\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_parser\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: RunnableParallel.__init__() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "chain = ( prompt_template |\n",
    "        llm_anthropic | \n",
    "        str_parser |\n",
    "        dict_maker_runnable | \n",
    "        RunnableParallel( \n",
    "            branch= {\"fb_post\": fb_post_maker_runnable \"news_post\": prompt_post_nw | llm_anthropic | str_parser},\n",
    "\n",
    "        )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
